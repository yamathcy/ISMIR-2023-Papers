# ISMIR-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v1.0.0-4FC528)
![GitHub repo size](https://img.shields.io/github/repo-size/yamathcy/ISMIR-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/yamathcy/ISMIR-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/yamathcy/ISMIR-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/yamathcy/ISMIR-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/yamathcy/ISMIR-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/yamathcy/ISMIR-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/yamathcy/ISMIR-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/yamathcy/ISMIR-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/yamathcy/ISMIR-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/yamathcy/ISMIR-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/yamathcy/ISMIR-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/yamathcy/ISMIR-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/yamathcy/ISMIR-2023-Papers)
![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2Fyamathcy%2FISMIR-2023-Papers&label=Visitors&countColor=%23263759&style=flat)

<div style="float:left;">
  <img src="https://geps.dev/progress/100?successColor=006600" />
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/completed_checkmark_done.svg" width="25" />
</div>

---

ISMIR 2023 Papers: A complete collection of influential and exciting research papers from the [*ISMIR 2023*](https://ismir2023.ismir.net/) conference. Explore the latest advances in Music information retrieval. Code included. :star:

<p align="center">
    <a href="https://ismir2023.ismir.net/" target="_blank">
        <img width="600" src="https://cdn.jsdelivr.net/gh/DmitryRyumin/ISMIR-2023-Papers@main/images/ISMIR2023-banner.jpg" alt="ISMIR 2023">
    </a>
<p>

![Total Papers](https://img.shields.io/badge/Total%20Papers-103-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-52%20(50.49%25)-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-45%20(43.69%25)%20*-1D7FBF)

> :point_right: `*` This count includes repositories on GitHub, GitLab, Hugging Face, and distributions on PyPI, while excluding Web Page or GitHub Page links.

---

[*The PDF version of the ISMIR 2023 Conference Programme*](https://ismir2023.ismir.net/assets/img/detailed_schedule.pdf), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> :exclamation: Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/CVPR-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>ICCV</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICCV-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech/Signal Processing (SP/SigProc)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/yamathcy/ISMIR-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=yamathcy/ISMIR-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/yamathcy/ISMIR-2023-Papers/pulls), [*open issues*](https://github.com/yamathcy/ISMIR-2023-Papers/issues) or contact me via [*email*](mailto:yyamamoto13044aa@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://ismir2023.ismir.net/)

<!-- > :exclamation: Final paper links will be added post-conference. -->

<details open>
<summary>List of sessions<a id="sections"></a></summary>

- [Session 1](#session-1)
- [Session 2](#session-2)
- [Session 3](#session-3)
- [Session 4](#session-4)
- [Session 5](#session-5)
- [Session 6](#session-6)
- [Session 7](#session-7)

</details>

<!-- <a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a> -->

### Session 1

![Session Papers](https://img.shields.io/badge/Session%20Papers-16-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-7-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-11-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| Exploring the Correspondence of Melodic Contour with Gesture in Raga Alap Singing | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://dap-lab.github.io/audioGestureCorrespondence/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://dap-lab.github.io/audioGestureCorrespondence/pdf/paper.pdf) |
| TriAD: Capturing Harmonics with 3D Convolutions | [![GitHub](https://img.shields.io/github/stars/migperfer/TriAD-ISMIR2023)](https://github.com/migperfer/TriAD-ISMIR2023) | :heavy_minus_sign: |
| Data Collection in Music Generation Training Sets: A Critical Analysis | [![GitHub](https://img.shields.io/github/stars/Sma1033/amgdatasetethics)](https://github.com/Sma1033/amgdatasetethics) | :heavy_minus_sign: |
| A Review of Validity and its Relationship to Music Information Research | [![GitHub](https://img.shields.io/github/stars/boblsturm/mirvaliditytutorial)](https://github.com/boblsturm/mirvaliditytutorial) | [![arXiv](https://img.shields.io/badge/arXiv-2301.01578-b31b1b.svg)](https://arxiv.org/abs/2301.01578) |
| Segmentation and Analysis of Taniavartanam in Carnatic Music Concerts | :heavy_minus_sign: | :heavy_minus_sign: |
| Transfer Learning and Bias Correction with Pre-Trained Audio Embeddings | [![GitHub](https://img.shields.io/github/stars/changhongw/audio-embedding-bias)](https://github.com/changhongw/audio-embedding-bias) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10834-b31b1b.svg)](https://arxiv.org/abs/2307.10834) |
| Collaborative Song Dataset (CoSoD): An Annotated Dataset of Multi-Artist Collaborations in Popular Music | [![GitHub](https://img.shields.io/github/stars/duguay-michele/CoSoD)](https://github.com/duguay-michele/CoSoD) | [![arXiv](https://img.shields.io/badge/arXiv-2307.05588-b31b1b.svg)](https://arxiv.org/abs/2307.05588) |
| Human-AI Music Creation: Understanding the Perceptions and Experiences of Music Creators for Ethical and Productive Collaboration | [![GitHub](https://img.shields.io/github/stars/michelenewman/ISMIR23_supplemental_material)](https://github.com/michelenewman/ISMIR23_supplemental_material) | :heavy_minus_sign: |
| Impact of Time and Note Duration Tokenizations on Deep Learning Symbolic Music Modeling| [![GitHub](https://img.shields.io/github/stars/Natooz/music-modeling-time-duration)](https://github.com/Natooz/music-modeling-time-duration) | [![arXiv](https://img.shields.io/badge/arXiv-2310.08497-b31b1b.svg)](https://arxiv.org/abs/2310.08497) |
| Musical Micro-Timing for Live Coding | [![GitHub](https://img.shields.io/github/stars/MaxTheComputerer/sonicpi-metre)](https://github.com/MaxTheComputerer/sonicpi-metre) | :heavy_minus_sign: |
| A Few-Shot Neural Approach for Layout Analysis of Music Score Image | [![GitHub](https://img.shields.io/github/stars/fjcastellanos/FewShotLayoutAnalysisMusic)](https://github.com/fjcastellanos/FewShotLayoutAnalysisMusic) | :heavy_minus_sign: |
| TapTamDrum: A Dataset for Dualized Drum Patterns | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://taptamdrum.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/taptamdrum/dataset)](https://github.com/taptamdrum/dataset) | :heavy_minus_sign: |
| Real-Time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar | [![GitHub](https://img.shields.io/github/stars/iamtheband/martelloni_et_al_ismir2023)](https://github.com/iamtheband/martelloni_et_al_ismir2023) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07426-b31b1b.svg)](https://arxiv.org/abs/2307.07426) |
| IteraTTA: An Interface for Exploring both Text Prompts and Audio Priors in Generating Music with Text-to-Audio Models | [![Demo](https://img.shields.io/badge/Demo-IteraTTA-FFD21F.svg)](https://iteratta.duckdns.org/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13005-b31b1b.svg)](https://arxiv.org/abs/2307.13005) |
| Similarity Evaluation of Violin Directivity Patterns for Musical Instrument Retrieval | :heavy_minus_sign: | :heavy_minus_sign: |
| Polyrhythmic Modelling of Non-Isochronous and Microtiming Patterns | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 2

![Session Papers](https://img.shields.io/badge/Session%20Papers-15-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-7-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-7-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| CLaMP: Contrastive Language-Music Pre-Training for Cross-Modal Symbolic Music Information Retrieval | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://microsoft.github.io/muzic/clamp/) <br /> [![GitHub](https://img.shields.io/github/stars/microsoft/muzic)](https://github.com/microsoft/muzic) | [![arXiv](https://img.shields.io/badge/arXiv-2304.11029-b31b1b.svg)](https://arxiv.org/abs/2304.11029) |
| Gender-Coded Sound: Analysing the Gendering of Music in Toy Commercials via Multi-Task Learning | [![GitHub](https://img.shields.io/github/stars/marinelliluca/gender_coded_sound_ismir2023)](https://github.com/marinelliluca/gender_coded_sound_ismir2023) | [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/372279840_Gender-Coded_Sound_Analysing_the_Gendering_of_Music_in_Toy_Commercials_via_Multi-Task_Learning) |
| A Dataset and Baselines for Measuring and Predicting the Music Piece Memorability | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Notation Assembly in Optical Music Recognition | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://repositori.upf.edu/bitstream/handle/10230/58186/Valero_ism_effi.pdf?sequence=1&isAllowed=y) |
| White Box Search over Audio Synthesizer Parameters | :heavy_minus_sign: | :heavy_minus_sign: |
| Decoding Drums, Instrumentals, Vocals, and Mixed Sources in Music using Human Brain Activity with fMRI | :heavy_minus_sign: | :heavy_minus_sign: |
| Dual Attention-based Multi-Scale Feature Fusion Approach for Dynamic Music Emotion Recognition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ismir-2023.github.io/MER1101/) | :heavy_minus_sign: |
| Automatic Piano Transcription with Hierarchical Frequency-Time Transformer | [![GitHub](https://img.shields.io/github/stars/sony/hFT-Transformer)](https://github.com/sony/hFT-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2307.04305-b31b1b.svg)](https://arxiv.org/abs/2307.04305) |
| High-Resolution Violin Transcription using Weak Labels | [![GitHub](https://img.shields.io/github/stars/MTG/violin-transcription)](https://github.com/MTG/violin-transcription) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://repositori.upf.edu/bitstream/handle/10230/58121/Tamer_ism_high.pdf?sequence=1&isAllowed=y) |
| Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://polyffusion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/aik2mlj/polyffusion)](https://github.com/aik2mlj/polyffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10304-b31b1b.svg)](https://arxiv.org/abs/2307.10304) |
| The Coordinated Corpus of Popular Musics (CoCoPops): A Meta-Dataset of Melodic and Harmonic Transcriptions | [![GitHub](https://img.shields.io/github/stars/Computational-Cognitive-Musicology-Lab/CoCoPops)](https://github.com/Computational-Cognitive-Musicology-Lab/CoCoPops) | :heavy_minus_sign: |
| Towards Computational Music Analysis for Music Therapy | :heavy_minus_sign: | :heavy_minus_sign: |
| Timbre Transfer using Image-to-Image Denoising Diffusion Implicit Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lucacoma.github.io/DiffTransfer/) <br /> [![GitHub](https://img.shields.io/github/stars/lucacoma/DiffTransfer)](https://github.com/lucacoma/DiffTransfer) | [![arXiv](https://img.shields.io/badge/arXiv-2307.04586-b31b1b.svg)](https://arxiv.org/abs/2307.04586) |
| Correlation of EEG Responses Reflects Structural Similarity of Choruses in Popular Music | :heavy_minus_sign: | :heavy_minus_sign: |
| Chromatic Chords in Theory and Practice | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 3

![Session Papers](https://img.shields.io/badge/Session%20Papers-16-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-8-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| BPS-Motif: A Dataset for Repeated Pattern Discovery of Polyphonic Symbolic Music | :heavy_minus_sign: | :heavy_minus_sign: |
| Weakly Supervised Multi-Pitch Estimation using Cross-Version Alignment | [![GitHub](https://img.shields.io/github/stars/groupmm/weakly_supervised_mpe)](https://github.com/groupmm/weakly_supervised_mpe) | :heavy_minus_sign: |
| The Batik-Plays-Mozart Corpus: Linking Performance to Score to Musicological Annotations | [![GitHub](https://img.shields.io/github/stars/huispaty/batik_plays_mozart)](https://github.com/huispaty/batik_plays_mozart) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02399-b31b1b.svg)](https://arxiv.org/abs/2309.02399) |
| Mono-to-Stereo through Parametric Stereo Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.14647-b31b1b.svg)](https://arxiv.org/abs/2306.14647) |
| From West to East: Who Can Understand the Music of the Others Better? | :heavy_minus_sign: | [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/372468858_From_West_to_East_Who_can_understand_the_music_of_the_others_better) |
| On the Performance of Optical Music Recognition in the Absence of Specific Training Data | :heavy_minus_sign: | :heavy_minus_sign: |
| Composer's Assistant: An Interactive Transformer for Multi-Track MIDI Infilling | [![GitHub](https://img.shields.io/github/stars/m-malandro/composers-assistant-REAPER)](https://github.com/m-malandro/composers-assistant-REAPER) | [![arXiv](https://img.shields.io/badge/arXiv-2301.12525-b31b1b.svg)](https://arxiv.org/abs/2301.12525) |
| The FAV Corpus: An Audio Dataset of Favorite Pieces and Excerpts, with Formal Analyses and Music Theory Descriptors | :heavy_minus_sign: | :heavy_minus_sign: |
| LyricWhiz: Robust Multilingual Lyrics Transcription by Whispering to ChatGPT | [![GitHub](https://img.shields.io/github/stars/zhuole1025/LyricWhiz)](https://github.com/zhuole1025/LyricWhiz) | [![arXiv](https://img.shields.io/badge/arXiv-2306.17103-b31b1b.svg)](https://arxiv.org/abs/2306.17103) |
| Sounds Out of Place? Score Independent Detection of Conspicuous Mistake Regions in MIDI Piano Performances | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/ismir2023-conspicuous-error) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://repositori.upf.edu/bitstream/handle/10230/58108/Morsi_ism_soun.pdf?sequence=1&isAllowed=y) |
| VampNet: Music Generation via Masked Acoustic Token Modeling | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://hugo-does-things.notion.site/VampNet-Music-Generation-via-Masked-Acoustic-Token-Modeling-e37aabd0d5f1493aa42c5711d0764b33) <br /> [![GitHub](https://img.shields.io/github/stars/hugofloresgarcia/vampnet)](https://github.com/hugofloresgarcia/vampnet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.04686-b31b1b.svg)](https://arxiv.org/abs/2307.04686) |
| Expert and Novice Evaluations of Piano Performances: Criteria for Computer-Aided Feedback | :heavy_minus_sign: | :heavy_minus_sign: |
| Contrastive Learning for Cross-Modal Artist Retrieval | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06556-b31b1b.svg)](https://arxiv.org/abs/2308.06556) |
| Repetition-Structure Inference with Formal Prototypes | [![GitHub](https://img.shields.io/github/stars/DCMLab/form-repetition-ismir23)](https://github.com/DCMLab/form-repetition-ismir23) | :heavy_minus_sign: |
| Algorithmic Harmonization of Tonal Melodies using Weighted Pitch Context Vectors | [![GitHub](https://img.shields.io/github/stars/pvankranenburg/ismir2023)](https://github.com/pvankranenburg/ismir2023) | :heavy_minus_sign: |
| Text-to-Lyrics Generation with Image-based Semantics and Reduced Risk of Plagiarism | [![GitHub](https://img.shields.io/github/stars/KentoW/ISMIR2023)](https://github.com/KentoW/ISMIR2023) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 4

![Session Papers](https://img.shields.io/badge/Session%20Papers-15-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-9-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-5-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| LP-MusicCaps: LLM-based Pseudo Music Captioning | [![GitHub](https://img.shields.io/github/stars/seungheondoh/lp-music-caps)](https://github.com/seungheondoh/lp-music-caps) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16372-b31b1b.svg)](https://arxiv.org/abs/2307.16372) |
| A Repetition-based Triplet Mining Approach for Music Segmentation | :heavy_minus_sign: | [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.science/hal-04202766) |
| Predicting Music Hierarchies with a Graph-based Neural Decoder | [![GitHub](https://img.shields.io/github/stars/fosfrancesco/musicparser)](https://github.com/fosfrancesco/musicparser) | [![arXiv](https://img.shields.io/badge/arXiv-2306.16955-b31b1b.svg)](https://arxiv.org/abs/2306.16955) |
| Stabilizing Training with Soft Dynamic Time Warping: A Case Study for Pitch Class Estimation with Weakly Aligned Targets | [![GitHub](https://img.shields.io/github/stars/groupmm/stabilizing_sdtw)](https://github.com/groupmm/stabilizing_sdtw) | [![arXiv](https://img.shields.io/badge/arXiv-2308.05429-b31b1b.svg)](https://arxiv.org/abs/2308.05429) |
| Finding Tori: Self-Supervised Learning for Analyzing Korean Folk Song | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://danbinaerinhan.github.io/korean-folksong-visualization/) <br /> [![GitHub](https://img.shields.io/github/stars/danbinaerinHan/finding-tori)](https://github.com/danbinaerinHan/finding-tori) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02249-b31b1b.svg)](https://arxiv.org/abs/2308.02249) |
| Singer Identity Representation Learning using Self-Supervised Techniques | [![GitHub](https://img.shields.io/github/stars/SonyCSLParis/ssl-singer-identity)](https://github.com/SonyCSLParis/ssl-singer-identity) | [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.science/hal-04186048) |
| On the Effectiveness of Speech Self-Supervised Learning for Music | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.05161-b31b1b.svg)](https://arxiv.org/abs/2307.05161) |
| Transformer-based Beat Tracking with Low-Resolution Encoder and High-Resolution Decoder | :heavy_minus_sign: | :heavy_minus_sign: |
| Adding Descriptors to Melodies Improves Pattern Matching: A Study on Slovenian Folk Songs | :heavy_minus_sign: | :heavy_minus_sign: |
| How Control and Transparency for Users Could Improve Artist Fairness in Music Recommender Systems | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://christinebauer.eu/publications/dinnissen2023_control/dinnissen2023_control.pdf) |
| Towards a New Interface for Music Listening: A User Experience Study on YouTube | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.14718-b31b1b.svg)](https://arxiv.org/abs/2307.14718) |
| FiloBass: A Dataset and Corpus based Study of Jazz Basslines | :heavy_minus_sign: | :heavy_minus_sign: |
| Comparing Texture in Piano Scores | :heavy_minus_sign: | :heavy_minus_sign: |
| Introducing DiMCAT for Processing and Analyzing Notated Music on a Very Large Scale | :heavy_minus_sign: | :heavy_minus_sign: |
| Sequence-to-Sequence Network Training Methods for Automatic Guitar Transcription with Tokenized Outputs | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 5

![Session Papers](https://img.shields.io/badge/Session%20Papers-16-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-6-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-7-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| PESTO: Pitch Estimation with Self-Supervised Transposition-Equivariant Objective | [![GitHub](https://img.shields.io/github/stars/SonyCSLParis/pesto)](https://github.com/SonyCSLParis/pesto) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02265-b31b1b.svg)](https://arxiv.org/abs/2309.02265) |
| The Games we Play: Exploring the Impact of ISMIR on Musicology | :heavy_minus_sign: | :heavy_minus_sign: |
| Carnatic Singing Voice Separation using Cold Diffusion on Training Data with Bleeding | [![GitHub](https://img.shields.io/github/stars/MTG/carnatic-separation-ismir23)](https://github.com/MTG/carnatic-separation-ismir23) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://repositori.upf.edu/bitstream/handle/10230/58188/Plaja_ism_carn.pdf?sequence=1&isAllowed=y) |
| Unveiling the Impact of Musical Factors in Judging a Song on First Listen: Insights from a User Survey | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Building a Phylogeny of Gregorian Chant Melodies | :heavy_minus_sign: | :heavy_minus_sign: |
| Audio Embeddings as Teachers for Music Classification | [![GitHub](https://img.shields.io/github/stars/suncerock/EAsT-music-classification)](https://github.com/suncerock/EAsT-music-classification) | [![arXiv](https://img.shields.io/badge/arXiv-2306.17424-b31b1b.svg)](https://arxiv.org/abs/2306.17424) |
| ScorePerformer: Expressive Piano Performance Rendering with Fine-Grained Control | :heavy_minus_sign: | :heavy_minus_sign: |
| Roman Numeral Analysis with Graph Neural Networks: Onset-Wise Predictions from Note-Wise Features | [![GitHub](https://img.shields.io/github/stars/manoskary/chordgnn)](https://github.com/manoskary/chordgnn) | [![arXiv](https://img.shields.io/badge/arXiv-2307.03544-b31b1b.svg)](https://arxiv.org/abs/2307.03544) |
| Semi-Automated Music Catalog Curation using Audio and Metadata | :heavy_minus_sign: | :heavy_minus_sign: |
| Crowd's Performance on Temporal Activity Detection of Musical Instruments in Polyphonic Music | :heavy_minus_sign: | :heavy_minus_sign: |
| MoisesDB: A Dataset for Source Separation Beyond 4 Stems | [![GitHub](https://img.shields.io/github/stars/moises-ai/moises-db)](https://github.com/moises-ai/moises-db) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15913-b31b1b.svg)](https://arxiv.org/abs/2307.15913) |
| Music as Flow: A Formal Representation of Hierarchical Processes in Music | :heavy_minus_sign: | :heavy_minus_sign: |
| Online Symbolic Music Alignment with Offline Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: |
| InverSinthII: Sound Matching via Self-Supervised Synthesizer-Proxy and Inference-Time Finetuning | :heavy_minus_sign: | :heavy_minus_sign: |
| A Semi-Supervised Deep Learning Approach to Dataset Collection for Query-by-Humming Task | [![GitHub](https://img.shields.io/github/stars/amanteur/CHAD)](https://github.com/amanteur/CHAD) | :heavy_minus_sign: |
| Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction | [![GitHub](https://img.shields.io/github/stars/SmoothKen/KKNet)](https://github.com/SmoothKen/KKNet) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02723-b31b1b.svg)](https://arxiv.org/abs/2308.02723) |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 6

![Session Papers](https://img.shields.io/badge/Session%20Papers-15-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-9-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-3-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| Singing Voice Synthesis using Differentiable LPC and Glottalflow Inspired Wavetables | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yoyololicon.github.io/golf-demo/) <br /> [![GitHub](https://img.shields.io/github/stars/yoyololicon/golf)](https://github.com/yoyololicon/golf) | [![arXiv](https://img.shields.io/badge/arXiv-2306.17252-b31b1b.svg)](https://arxiv.org/abs/2306.17252) |
| Harmonic Analysis with Neural Semi-CRF | :heavy_minus_sign: | :heavy_minus_sign: |
| A Dataset and Baseline for Automated Assessment of Timbre Quality in Trumpet Sound | [![GitHub](https://img.shields.io/github/stars/PNinad/ISMIR2023)](https://github.com/PNinad/ISMIR2023) <br /> [![Dataset](https://zenodo.org/badge/DOI/10.5281/zenodo.8132780.svg)](https://doi.org/10.5281/zenodo.8132780) | :heavy_minus_sign: |
| Visual Overviews for Sheet Music Structure | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06140-b31b1b.svg)](https://arxiv.org/abs/2308.06140) |
| Passage Summarization with Recurrent Models for Audio â€“ Sheet Music Retrieval | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.12111-b31b1b.svg)](https://arxiv.org/abs/2309.12111) |
| Predicting Performance Difficulty from Piano Sheet Music Images | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.16287-b31b1b.svg)](https://arxiv.org/abs/2309.16287) |
| Self-Refining of Pseudo Labels for Music Source Separation with Noisy Labeled Data | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.12576-b31b1b.svg)](https://arxiv.org/abs/2307.12576) |
| Quantifying the Ease of Playing Song Chords on the Guitar | :heavy_minus_sign: | :heavy_minus_sign: |
| FlexDTW: Dynamic Time Warping with Flexible Boundary Conditions | :heavy_minus_sign: | :heavy_minus_sign: |
| Modeling Bends in Popular Music Guitar Tablatures | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.12307-b31b1b.svg)](https://arxiv.org/abs/2308.12307) |
| Self-Similarity-based and Novelty-based Loss for Music Structure Analysis | [![GitHub](https://img.shields.io/github/stars/geoffroypeeters/ssmnet_ISMIR2023)](https://github.com/geoffroypeeters/ssmnet_ISMIR2023) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02243-b31b1b.svg)](https://arxiv.org/abs/2309.02243) |
| Modeling Harmonic Similarity for Jazz using Cooccurrence Vectors and the Membrane Area | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/90562/Bunks%20Modeling%20Harmonic%20Similarity%20for%20Jazz%20Using%20Co-occurrence%20Vectors%20and%20the%20Membrane%20Area%202023%20Accepted.pdf?sequence=2&isAllowed=n) |
| SingStyle111: A Multilingual Singing Dataset with Style Transfer | :heavy_minus_sign: | :heavy_minus_sign: |
| A Computational Evaluation Framework for Singable Lyric Translation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.13715-b31b1b.svg)](https://arxiv.org/abs/2308.13715) |
| Chorus-Playlist: Exploring the Impact of Listening to Only Choruses in a Playlist | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 7

![Session Papers](https://img.shields.io/badge/Session%20Papers-10-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-6-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-4-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| Supporting Musicological Investigations with Information Retrieval Tools: An Iterative Approach to Data Collection | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://research.gold.ac.uk/id/eprint/34165/1/BitH_ISMIR_2023-camera-ready.pdf) |
| Optimizing Feature Extraction for Symbolic Music | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://musif.didone.eu/) <br /> [![GitHub](https://img.shields.io/github/stars/DIDONEproject/music_symbolic_features)](https://github.com/DIDONEproject/music_symbolic_features) | [![arXiv](https://img.shields.io/badge/arXiv-2307.05107-b31b1b.svg)](https://arxiv.org/abs/2307.05107) |
| Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09454-b31b1b.svg)](https://arxiv.org/abs/2308.09454) |
| Measuring the Eurovision Song Contest: A Living Dataset for Real-World MIR | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Supervised Training of Audio Transformers for Music Representation Learning | [![GitHub](https://img.shields.io/github/stars/palonso/MAEST)](https://github.com/palonso/MAEST) | [![arXiv](https://img.shields.io/badge/arXiv-2309.16418-b31b1b.svg)](https://arxiv.org/abs/2309.16418) |
| A Cross-Version Approach to Audio Representation Learning for Orchestral Music | [![GitHub](https://img.shields.io/github/stars/groupmm/cross_version_learning)](https://github.com/groupmm/cross_version_learning) | :heavy_minus_sign: |
| Music Source Separation with MLP Mixing of Time, Frequency, and Channel | :heavy_minus_sign: | :heavy_minus_sign: |
| Symbolic Music Representations for Classification Tasks: A Systematic Evaluation | [![GitHub](https://img.shields.io/github/stars/anusfoil/SymRep)](https://github.com/anusfoil/SymRep) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02567-b31b1b.svg)](https://arxiv.org/abs/2309.02567) |
| The Music Meta Ontology: A Flexible Semantic Model for the Interoperability of Music Metadata | :heavy_minus_sign: | :heavy_minus_sign: |
| Polar Manhattan Displacement: Measuring Tonal Distances between Chords based on Intervallic Content | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/89900/Pauwels%20Polar%20Manhattan%20Displacement%3a%20measuring%20tonal%20distances%20between%20chords%20based%20on%20intervallic%20content%202023%20Accepted.pdf?sequence=2&isAllowed=y) |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Late-Breaking Demo

> Will soon be added

---

## Star History

<p align="center">
    <a href="https://star-history.com/#yamathcy/ISMIR-2023-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=yamathcy/ISMIR-2023-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
